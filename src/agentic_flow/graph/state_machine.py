"""
LangGraph State Machine Core Implementation

This module implements the core state machine logic for the NL-to-SQL pipeline,
including state definitions, node connections, and conditional routing.
"""

import time
import logging
from typing import Dict, List, Optional, Any, TypedDict, Union, Callable
from dataclasses import dataclass
from enum import Enum

from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.memory import MemorySaver

from ..nodes import (
    NLProcessor, SQLGenerationNode, 
    SQLValidationNode, DataSummarizationNode
)
# SchemaMapper ì œê±°: RAGSchemaRetrieverNodeì— í†µí•©ë¨
# from ..nodes import SchemaMapper
from ..llm_intent_classifier import LLMIntentClassifier
# DynamicSQLGenerator í†µí•©ìœ¼ë¡œ ì¸í•œ import ì œê±°
# from ..dynamic_sql_generator import DynamicSQLGenerator
from ..rag_schema_retriever import RAGSchemaRetrieverNode
from ..validation_node import ValidationNode
from ..user_review_node import UserReviewNode, ReviewStatus
from ..python_code_generator import PythonCodeGeneratorNode
from ..code_executor import CodeExecutorNode
from ..result_integrator import ResultIntegratorNode
from ..hybrid_query_processor import HybridQueryProcessor
from ..monitoring import PipelineMonitor
# ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ import
from ..utils import is_intent_equal, is_intent_in
from core.config import get_settings
from core.db import get_db_session, execute_query
from core.logging import get_logger

logger = get_logger(__name__)


class ExecutionStatus(Enum):
    """Execution status enumeration."""
    PENDING = "pending"
    IN_PROGRESS = "in_progress"
    COMPLETED = "completed"
    FAILED = "failed"
    RETRYING = "retrying"


class NodeType(Enum):
    """Node type enumeration."""
    LLM_INTENT_CLASSIFICATION = "llm_intent_classification"
    NLP_PROCESSING = "nlp_processing"
    # SCHEMA_MAPPING = "schema_mapping"  # ì œê±°: RAGSchemaRetrieverNodeì— í†µí•©ë¨
    # DynamicSQLGenerator í†µí•©ìœ¼ë¡œ ì¸í•œ ë…¸ë“œ ì œê±°
    # DYNAMIC_SQL_GENERATION = "dynamic_sql_generation"
    SQL_GENERATION = "sql_generation"
    SQL_VALIDATION = "sql_validation"
    VALIDATION_CHECK = "validation_check"
    USER_REVIEW = "user_review"
    SQL_EXECUTION = "sql_execution"
    DATA_SUMMARIZATION = "data_summarization"


@dataclass
class NodeExecutionResult:
    """Result of node execution."""
    node_type: NodeType
    success: bool
    execution_time: float
    confidence: float
    error_message: Optional[str] = None
    metadata: Optional[Dict[str, Any]] = None


class AgentState(TypedDict):
    """
    State definition for the LangGraph pipeline.
    
    This TypedDict defines all the data that flows through the pipeline,
    including input, intermediate results, and output.
    """
    # Input
    user_query: str
    user_id: Optional[str]
    channel_id: Optional[str]
    session_id: Optional[str]
    context: Optional[Dict[str, Any]]
    
    # Processing stages
    normalized_query: Optional[str]
    intent: Optional[str]
    llm_intent_result: Optional[Dict[str, Any]]
    entities: List[Dict[str, Any]]
    agent_schema_mapping: Optional[Dict[str, Any]]
    sql_query: Optional[str]
    validated_sql: Optional[str]
    sql_params: Optional[Dict[str, Any]]  # SQL íŒŒë¼ë¯¸í„° (SQL Injection ë°©ì§€)
    query_result: List[Dict[str, Any]]
    data_summary: Optional[str]
    
    # Conversation handling
    skip_sql_generation: Optional[bool]
    conversation_response: Optional[str]
    needs_clarification: Optional[bool]  # ì‚¬ìš©ì ì¬ì…ë ¥ì´ í•„ìš”í•œì§€ í‘œì‹œ
    
    # Fanding templates
    fanding_template: Optional[Any]
    
    # Validation and error handling
    validation_result: Optional[Dict[str, Any]]
    processing_decision: Optional[Dict[str, Any]]
    is_valid: bool
    error_message: Optional[str]
    retry_count: int
    max_retries: int
    
    # Execution tracking
    current_node: Optional[str]
    execution_status: str
    node_results: List[NodeExecutionResult]
    
    # Metadata
    processing_time: float
    execution_time: float
    confidence_scores: Dict[str, float]
    debug_info: Dict[str, Any]
    
    # RAG schema retrieval
    rag_schema_chunks: Optional[List[Dict[str, Any]]]  # RAG schema retrieval results
    rag_schema_context: Optional[str]  # Formatted schema context for prompts
    
    # Conversation history for context awareness
    conversation_history: Optional[List[Dict[str, str]]]  # [{"role": "user|assistant", "content": "..."}]
    
    # Additional fields for review
    review_status: Optional[str]
    review_result: Optional[Any]
    
    # Output
    final_sql: Optional[str]
    explanation: Optional[str]
    success: bool


def _create_performance_wrapper(node_name: str, node_func: Callable[[AgentState], AgentState]) -> Callable[[AgentState], AgentState]:
    """
    ë…¸ë“œ ì‹¤í–‰ ì‹œê°„ ì¸¡ì • ë° ì„±ëŠ¥ ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘ ë˜í¼
    
    Args:
        node_name: ë…¸ë“œ ì´ë¦„
        node_func: ì‹¤ì œ ë…¸ë“œ í•¨ìˆ˜
        
    Returns:
        ì„±ëŠ¥ ì¸¡ì • ê¸°ëŠ¥ì´ ì¶”ê°€ëœ ë…¸ë“œ í•¨ìˆ˜
    """
    def wrapper(state: AgentState) -> AgentState:
        node_start_time = time.time()
        state["current_node"] = node_name
        
        try:
            result = node_func(state)
            node_execution_time = time.time() - node_start_time
            
            # ì„±ëŠ¥ ë©”íƒ€ë°ì´í„° ì¶”ê°€
            # debug_infoê°€ ì—†ìœ¼ë©´ ì´ˆê¸°í™”, ìˆìœ¼ë©´ ê¸°ì¡´ ê²ƒì„ ì‚¬ìš©
            if "debug_info" not in result:
                result["debug_info"] = {}
            elif result["debug_info"] is None:
                result["debug_info"] = {}
            
            # node_performance ì´ˆê¸°í™” (ê¸°ì¡´ ë°ì´í„° ìœ ì§€)
            if "node_performance" not in result["debug_info"]:
                result["debug_info"]["node_performance"] = {}
            
            # ë…¸ë“œë³„ ì¶”ê°€ ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘
            metadata = {
                "execution_time": node_execution_time,
                "success": True
            }
            
            # ë…¸ë“œë³„ íŠ¹ìˆ˜ ë©”íŠ¸ë¦­ ì¶”ê°€
            if node_name == "rag_schema_retrieval":
                metadata["chunks_retrieved"] = len(result.get("rag_schema_chunks", []))
            elif node_name == "sql_generation":
                if result.get("sql_query"):
                    metadata["sql_length"] = len(result.get("sql_query", ""))
                    metadata["sql_generated"] = True
                else:
                    metadata["sql_generated"] = False
            # DynamicSQLGenerator í†µí•©ìœ¼ë¡œ ì¸í•œ ë…¸ë“œ ì œê±°
            # dynamic_sql_resultëŠ” ì´ì œ SQLGenerationNodeì—ì„œ ìƒì„±ë˜ë¯€ë¡œ
            # sql_generation ë…¸ë“œì˜ ë©”íƒ€ë°ì´í„°ì—ì„œ ì²˜ë¦¬ë¨
            elif node_name == "llm_intent_classification":
                intent_result = result.get("llm_intent_result")
                if intent_result:
                    metadata["intent"] = intent_result.get("intent", "UNKNOWN")
                    metadata["confidence"] = intent_result.get("confidence", 0.0)
            elif node_name == "validation_check":
                validation_result = result.get("validation_result", {})
                if isinstance(validation_result, dict):
                    metadata["validation_passed"] = validation_result.get("status") != "FAILED"
                    metadata["validation_confidence"] = validation_result.get("confidence", 0.0)
            
            result["debug_info"]["node_performance"][node_name] = metadata
            
            logger.debug(f"Node {node_name} completed in {node_execution_time:.3f}s")
            return result
            
        except Exception as e:
            node_execution_time = time.time() - node_start_time
            logger.error(f"Node {node_name} failed after {node_execution_time:.3f}s: {str(e)}")
            
            # ì—ëŸ¬ ì •ë³´ë¥¼ debug_infoì— ì¶”ê°€
            if "debug_info" not in state:
                state["debug_info"] = {}
            if "node_performance" not in state["debug_info"]:
                state["debug_info"]["node_performance"] = {}
            
            state["debug_info"]["node_performance"][node_name] = {
                "execution_time": node_execution_time,
                "success": False,
                "error": str(e)
            }
            
            # ì—ëŸ¬ ìƒíƒœ ì„¤ì •
            state["error_message"] = f"{node_name} failed: {str(e)}"
            return state
    
    return wrapper


def _identify_bottlenecks(node_performance: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:
    """
    ë…¸ë“œ ì„±ëŠ¥ ë°ì´í„°ì—ì„œ ë³‘ëª© ì§€ì  ì‹ë³„
    
    Args:
        node_performance: ë…¸ë“œë³„ ì„±ëŠ¥ ë©”íŠ¸ë¦­
        
    Returns:
        ë³‘ëª© ì§€ì  ë¶„ì„ ê²°ê³¼
    """
    if not node_performance:
        return {
            "bottleneck_nodes": [],
            "total_time": 0.0,
            "analysis": "No performance data available"
        }
    
    # ì‹¤í–‰ ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
    node_times = {
        node_name: metrics.get("execution_time", 0.0)
        for node_name, metrics in node_performance.items()
    }
    
    total_time = sum(node_times.values())
    
    if total_time == 0:
        return {
            "bottleneck_nodes": [],
            "total_time": 0.0,
            "analysis": "No execution time data available"
        }
    
    # ì‹¤í–‰ ì‹œê°„ ê¸°ì¤€ ì •ë ¬
    sorted_nodes = sorted(node_times.items(), key=lambda x: x[1], reverse=True)
    
    # ì´ ì‹œê°„ì˜ 20% ì´ìƒì„ ì°¨ì§€í•˜ëŠ” ë…¸ë“œë¥¼ ë³‘ëª©ìœ¼ë¡œ ì‹ë³„
    bottleneck_threshold = total_time * 0.2
    bottleneck_nodes = [
        {
            "node_name": node_name,
            "execution_time": exec_time,
            "percentage": (exec_time / total_time) * 100,
            "metrics": node_performance[node_name]
        }
        for node_name, exec_time in sorted_nodes
        if exec_time >= bottleneck_threshold
    ]
    
    # í‰ê·  ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
    avg_time = total_time / len(node_times)
    
    # ìµœì í™” ì œì•ˆ ìƒì„±
    optimization_suggestions = []
    for node in bottleneck_nodes:
        node_name = node["node_name"]
        percentage = node["percentage"]
        
        if percentage > 50:
            optimization_suggestions.append({
                "node": node_name,
                "priority": "high",
                "suggestion": f"{node_name}ê°€ ì „ì²´ ì‹¤í–‰ ì‹œê°„ì˜ {percentage:.1f}%ë¥¼ ì°¨ì§€í•©ë‹ˆë‹¤. ìºì‹± ë˜ëŠ” ìµœì í™”ë¥¼ ê³ ë ¤í•˜ì„¸ìš”."
            })
        elif percentage > 30:
            optimization_suggestions.append({
                "node": node_name,
                "priority": "medium",
                "suggestion": f"{node_name}ê°€ ì „ì²´ ì‹¤í–‰ ì‹œê°„ì˜ {percentage:.1f}%ë¥¼ ì°¨ì§€í•©ë‹ˆë‹¤. ìµœì í™” ì—¬ì§€ê°€ ìˆìŠµë‹ˆë‹¤."
            })
    
    return {
        "bottleneck_nodes": bottleneck_nodes,
        "total_time": total_time,
        "average_node_time": avg_time,
        "slowest_node": sorted_nodes[0][0] if sorted_nodes else None,
        "fastest_node": sorted_nodes[-1][0] if sorted_nodes else None,
        "optimization_suggestions": optimization_suggestions,
        "node_count": len(node_times)
    }


def create_agent_graph(
    db_schema: Optional[Dict[str, Any]] = None,
    config: Optional[Dict[str, Any]] = None,
    checkpointer: Optional[Any] = None
) -> Any:
    """
    Create the LangGraph state machine for NL-to-SQL processing.
    
    Args:
        db_schema: Database schema information
        config: Configuration parameters
        
    Returns:
        Compiled StateGraph instance
    """
    logger.info("Creating LangGraph state machine")
    
    # Get configuration
    settings = get_settings()
    
    # db_schemaê°€ ì œê³µë˜ì§€ ì•Šìœ¼ë©´ get_cached_db_schema()ë¡œ ë¡œë“œ (ì„±ëŠ¥ ìµœì í™”)
    if db_schema is None or len(db_schema) == 0:
        from core.db import get_cached_db_schema
        db_schema = get_cached_db_schema()
        logger.debug("db_schema was not provided, loaded from cache during graph creation")
    
    if config is None:
        config = {
            "llm": {
                "model": settings.llm.model,
                "api_key": settings.llm.api_key,
                "temperature": settings.llm.temperature,
                "max_tokens": settings.llm.max_tokens
            },
            "db_schema": db_schema,  # ì´ë¯¸ ë¡œë“œëœ db_schema ì‚¬ìš©
            "max_retries": settings.pipeline.max_retries,
            "confidence_threshold": settings.pipeline.confidence_threshold,
            "enable_debug": settings.pipeline.enable_debug,
            "enable_monitoring": settings.pipeline.enable_monitoring
        }
    else:
        # configê°€ ì œê³µë˜ì—ˆì§€ë§Œ db_schemaê°€ ì—†ìœ¼ë©´ ì¶”ê°€
        if "db_schema" not in config or not config.get("db_schema") or len(config.get("db_schema", {})) == 0:
            config["db_schema"] = db_schema
            logger.debug("db_schema was missing in provided config, added from parameter")
    
    # Create the state graph
    graph = StateGraph(AgentState)
    
    # Initialize nodes
    nodes = _initialize_nodes(config)
    
    # Add nodes to the graph with performance monitoring wrappers
    # ëª¨ë“  ë…¸ë“œì— ì„±ëŠ¥ ì¸¡ì • ë˜í¼ ì ìš©
    graph.add_node(
        "llm_intent_classification",
        _create_performance_wrapper("llm_intent_classification", lambda state: nodes["llm_intent_classifier"].process(state))
    )
    
    graph.add_node(
        "nlp_processing",
        _create_performance_wrapper("nlp_processing", lambda state: nodes["nlp_processor"].process(state))
    )
    
    # schema_mapping ë…¸ë“œ ì œê±°: RAGSchemaRetrieverNodeì— í†µí•©ë¨
    # RAG ë…¸ë“œ: ì—ëŸ¬ ë°œìƒ ì‹œ í´ë°± ì²˜ë¦¬ ë° ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í¬í•¨
    def _rag_node_with_fallback(state: AgentState) -> AgentState:
        """RAG ë…¸ë“œ ì‹¤í–‰, ì—ëŸ¬ ì²˜ë¦¬ ë° ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§"""
        node_start_time = time.time()
        state["current_node"] = "rag_schema_retrieval"
        
        try:
            result = nodes["rag_schema_retriever"].process(state)
            node_execution_time = time.time() - node_start_time
            
            # ì„±ëŠ¥ ë©”íƒ€ë°ì´í„° ì¶”ê°€
            if "debug_info" not in result:
                result["debug_info"] = {}
            if "node_performance" not in result["debug_info"]:
                result["debug_info"]["node_performance"] = {}
            
            result["debug_info"]["node_performance"]["rag_schema_retrieval"] = {
                "execution_time": node_execution_time,
                "success": True,
                "chunks_retrieved": len(result.get("rag_schema_chunks", []))
            }
            
            logger.debug(f"RAG retrieval completed in {node_execution_time:.3f}s, retrieved {len(result.get('rag_schema_chunks', []))} chunks")
            return result
        except Exception as e:
            node_execution_time = time.time() - node_start_time
            logger.warning(f"RAG retrieval failed after {node_execution_time:.3f}s: {e}, continuing without RAG context")
            
            # ì—ëŸ¬ ë°œìƒ ì‹œ RAG í•„ë“œë¥¼ ë¹ˆ ê°’ìœ¼ë¡œ ì„¤ì •í•˜ê³  ê³„ì† ì§„í–‰
            state["rag_schema_chunks"] = []
            state["rag_schema_context"] = None
            
            # ì—ëŸ¬ ì •ë³´ë¥¼ debug_infoì— ì¶”ê°€
            if "debug_info" not in state:
                state["debug_info"] = {}
            if "node_performance" not in state["debug_info"]:
                state["debug_info"]["node_performance"] = {}
            
            state["debug_info"]["node_performance"]["rag_schema_retrieval"] = {
                "execution_time": node_execution_time,
                "success": False,
                "error": str(e),
                "chunks_retrieved": 0
            }
            
            return state
    
    graph.add_node("rag_schema_retrieval", _rag_node_with_fallback)
    
    # dynamic_sql_generation ë…¸ë“œ ì œê±° (SQLGenerationNodeì— í†µí•©ë¨)
    # graph.add_node(
    #     "dynamic_sql_generation",
    #     _create_performance_wrapper("dynamic_sql_generation", lambda state: nodes["dynamic_sql_generator"].process(state))
    # )

    graph.add_node(
        "sql_generation",
        _create_performance_wrapper("sql_generation", lambda state: nodes["sql_generator"].process(state))
    )

    graph.add_node(
        "sql_validation",
        _create_performance_wrapper("sql_validation", lambda state: nodes["sql_validator"].process(state))
    )
    
    graph.add_node(
        "validation_check",
        _create_performance_wrapper("validation_check", lambda state: nodes["validation_node"].process(state))
    )
    
    graph.add_node(
        "user_review",
        _create_performance_wrapper("user_review", lambda state: nodes["user_review_node"].process(state))
    )
    
    graph.add_node(
        "sql_execution",
        _create_performance_wrapper("sql_execution", _execute_sql_query)
    )
    
    graph.add_node(
        "data_summarization",
        _create_performance_wrapper("data_summarization", lambda state: nodes["data_summarizer"].process(state))
    )
    
    # Python ê²½ë¡œ ë…¸ë“œ ì¶”ê°€ (í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ)
    graph.add_node(
        "python_code_generation",
        _create_performance_wrapper("python_code_generation", lambda state: nodes["python_code_generator"].process(state))
    )
    
    graph.add_node(
        "code_execution",
        _create_performance_wrapper("code_execution", lambda state: nodes["code_executor"].process(state))
    )
    
    graph.add_node(
        "result_integration",
        _create_performance_wrapper("result_integration", lambda state: nodes["result_integrator"].process(state))
    )
    
    # Define the flow
    graph.add_edge(START, "llm_intent_classification")
    
    # Conditional edge after intent classification (3ê°ˆë˜ ë¶„ê¸°: ì¤‘ì•™ ê´€ì œíƒ‘/ê´€ë¬¸)
    # ìµœì í™”: CHAT_PATHëŠ” nlp_processingì„ ê±´ë„ˆë›°ê³  ë°”ë¡œ data_summarizationìœ¼ë¡œ ì§í–‰
    graph.add_conditional_edges(
        "llm_intent_classification",
        route_after_intent_classification,
        {
            "CHAT_PATH": "data_summarization",  # CHAT_PATH: ì¸ì‚¬/ë„ì›€ë§ (ì¦‰ì‹œ ì‘ë‹µ, nlp_processing ê±´ë„ˆë›°ê¸°)
            "SQL_PATH": "nlp_processing",       # SQL_PATH: SIMPLE_AGGREGATION (Fast Path)
            "PYTHON_PATH": "nlp_processing"     # PYTHON_PATH: COMPLEX_ANALYSIS (Safe Path)
        }
    )
    
    # Conditional edge after NLP processing
    # ë°ì´í„° ê²½ë¡œë§Œ ì—¬ê¸°ë¥¼ ê±°ì¹¨ (CHAT_PATHëŠ” ì´ë¯¸ llm_intent_classificationì—ì„œ ë°”ë¡œ data_summarizationìœ¼ë¡œ ê°)
    # ìµœì í™”: schema_mapping ë…¸ë“œ ì œê±°, nlp_processingì—ì„œ ì§ì ‘ rag_schema_retrievalë¡œ ì—°ê²°
    graph.add_conditional_edges(
        "nlp_processing",
        route_after_nlp_processing,
        {
            "SQL_PATH": "rag_schema_retrieval",        # SQL_PATH: SIMPLE_AGGREGATION (RAG ìŠ¤í‚¤ë§ˆ ê²€ìƒ‰ìœ¼ë¡œ ì§ì ‘ ì´ë™)
            "PYTHON_PATH": "rag_schema_retrieval",     # PYTHON_PATH: COMPLEX_ANALYSIS (RAG ìŠ¤í‚¤ë§ˆ ê²€ìƒ‰ìœ¼ë¡œ ì§ì ‘ ì´ë™)
            "end": END                                  # ì¡°ê¸° ì¢…ë£Œ (ëª…í™•í™” ì§ˆë¬¸ ë“±)
        }
    )
    
    # === SQL_PATH í”Œë¡œìš° (Fast Path âš¡) ===
    # schema_mapping ë…¸ë“œ ì œê±°ë¨, rag_schema_retrievalì´ schema_mapping ê¸°ëŠ¥ í¬í•¨
    
    # RAG ê²€ìƒ‰ í›„ intent ê¸°ë°˜ ë¼ìš°íŒ…
    # COMPLEX_ANALYSIS: SQL ìƒì„± ê±´ë„ˆë›°ê³  ë°”ë¡œ python_code_generationìœ¼ë¡œ
    # SIMPLE_AGGREGATION: sql_generationìœ¼ë¡œ
    graph.add_conditional_edges(
        "rag_schema_retrieval",
        route_after_rag_retrieval,
        {
            "sql_generation": "sql_generation",  # SQL_PATH: SIMPLE_AGGREGATION
            "python_code_generation": "python_code_generation"  # PYTHON_PATH: COMPLEX_ANALYSIS
        }
    )
    
    # ë” ë‹¨ìˆœí•œ ëŒ€ì•ˆ - ì¡°ê±´ë¶€ ë¡œì§ ì™„ì „ ì œê±° (í–¥í›„ ê³ ë ¤)
    # graph.add_edge("rag_schema_retrieval", "sql_generation")  # ëª¨ë“  ê²½ìš°ì— ì§ì ‘ ì—°ê²°
    
    # dynamic_sql_generation ë…¸ë“œ ì œê±°ë¡œ ì¸í•œ ì—£ì§€ ì œê±°
    # graph.add_edge("dynamic_sql_generation", "sql_generation")
    
    # SQL ìƒì„± í›„: SQL_PATHë§Œ ì—¬ê¸°ë¥¼ ê±°ì¹¨ (PYTHON_PATHëŠ” ì´ë¯¸ rag_schema_retrievalì—ì„œ python_code_generationìœ¼ë¡œ ë¼ìš°íŒ…ë¨)
    # í•˜ì§€ë§Œ ì˜ˆì™¸ ìƒí™©(fallback)ì„ ëŒ€ë¹„í•´ python_code_generation ê²½ë¡œë„ í¬í•¨
    graph.add_conditional_edges(
        "sql_generation",
        route_after_sql_generation,
        {
            "sql_validation": "sql_validation",  # SQL_PATH: Fast Path (ê²€ì¦ í›„ ë°”ë¡œ ì‹¤í–‰)
            "python_code_generation": "python_code_generation"  # Fallback: COMPLEX_ANALYSISê°€ ì—¬ê¸°ì— ë„ë‹¬í•œ ê²½ìš° (ì¼ë°˜ì ìœ¼ë¡œ ë°œìƒí•˜ì§€ ì•Šì•„ì•¼ í•¨)
        }
    )
    
    # === PYTHON_PATH í”Œë¡œìš° (Safe Path ğŸ) ===
    # Python ê²½ë¡œëŠ” RAGë¥¼ ê±°ì³ python_code_generatorë¡œ ì§ì ‘ ì´ë™
    # python_code_generatorê°€ data_gathering_sqlê³¼ python_codeë¥¼ ëª¨ë‘ ìƒì„±
    # ì´í›„ sql_execution â†’ code_execution ìˆœì„œë¡œ ì§„í–‰
    
    # SQL ê²€ì¦ í›„ ë¼ìš°íŒ…
    # Phase 1: SIMPLE_AGGREGATION Fast Path - ê²€ì¦ í†µê³¼ ì‹œ ë°”ë¡œ ì‹¤í–‰
    graph.add_conditional_edges(
        "sql_validation",
        route_after_validation,
        {
            "retry": "sql_generation",  # ì¬ì‹œë„
            "validate": "validation_check",  # ë‚®ì€ ì‹ ë¢°ë„ ë˜ëŠ” ê¸°íƒ€ ì˜ë„ (ì•ˆì „ì¥ì¹˜)
            "sql_execution": "sql_execution"  # Fast Path: SIMPLE_AGGREGATION ê²€ì¦ í†µê³¼ ì‹œ ë°”ë¡œ ì‹¤í–‰
        }
    )
    
    # ê²€ì¦ ì²´í¬ í›„ ë¼ìš°íŒ…
    graph.add_conditional_edges(
        "validation_check",
        route_after_validation_check,
        {
            "sql_execution": "sql_execution",  # ìë™ ìŠ¹ì¸ ë˜ëŠ” ì‚¬ìš©ì ìŠ¹ì¸
            "user_review": "user_review",  # ì‚¬ìš©ì ê²€í†  í•„ìš”
            "reject": "nlp_processing",  # ê±°ë¶€ (ì¬ì‹œì‘)
            "result_integration": "result_integration"  # ì´ë¯¸ SQL ì‹¤í–‰ëœ ê²½ìš° (ì¼ë°˜ì ìœ¼ë¡œ ë°œìƒí•˜ì§€ ì•ŠìŒ)
        }
    )
    
    # ì‚¬ìš©ì ê²€í†  í›„ ë¼ìš°íŒ…
    graph.add_conditional_edges(
        "user_review",
        route_after_user_review,
        {
            "sql_execution": "sql_execution",  # ì‚¬ìš©ì ìŠ¹ì¸
            "reject": "nlp_processing",  # ê±°ë¶€ (ì¬ì‹œì‘)
            "modify": "sql_generation",  # ìˆ˜ì • (SQL ì¬ìƒì„±)
            "pending": END  # ëŒ€ê¸° ì¤‘
        }
    )
    
    # === SQL ì‹¤í–‰ í›„ ë¼ìš°íŒ… (SQL_PATH vs PYTHON_PATH ë¶„ê¸°) ===
    # SQL_PATH: sql_execution â†’ result_integration
    # PYTHON_PATH: sql_execution â†’ code_execution (Python ì½”ë“œ ì‹¤í–‰)
    graph.add_conditional_edges(
        "sql_execution",
        route_after_sql_execution,
        {
            "result_integration": "result_integration",  # SQL_PATH: ê²°ê³¼ í†µí•©
            "code_execution": "code_execution"           # PYTHON_PATH: Python ì½”ë“œ ì‹¤í–‰
        }
    )
    
    # === PYTHON_PATH í”Œë¡œìš° ê³„ì† (Safe Path ğŸ) ===
    # python_code_generationì—ì„œ data_gathering_sqlê³¼ python_codeë¥¼ ìƒì„±
    # ë‹¤ìŒ ë…¸ë“œ: sql_execution (data_gathering_sql ì‹¤í–‰)
    graph.add_edge("python_code_generation", "sql_execution")
    
    # Python ê²½ë¡œìš© SQL ì‹¤í–‰: data_gathering_sql ì‹¤í–‰ (ê°„ë‹¨í•œ SQLì´ë¯€ë¡œ ë³µì¡í•œ ê²€ì¦ ë¶ˆí•„ìš”)
    # sql_execution ë…¸ë“œëŠ” ê¸°ì¡´ ê²ƒì„ ì¬ì‚¬ìš© (ì˜ë„ì— ë”°ë¼ ê°„ë‹¨/ë³µì¡ ê²€ì¦ ì„ íƒ)
    
    # Python ì½”ë“œ ì‹¤í–‰ í›„: ì„±ê³µ ì‹œ ê²°ê³¼ í†µí•©, ì‹¤íŒ¨ ì‹œ SQL ê²½ë¡œë¡œ í´ë°±
    graph.add_conditional_edges(
        "code_execution",
        route_after_code_execution,
        {
            "result_integration": "result_integration",  # ì„±ê³µ: ê²°ê³¼ í†µí•©
            "sql_validation": "sql_validation"  # ì‹¤íŒ¨: SQL ê²½ë¡œë¡œ í´ë°± (ê²€ì¦ë¶€í„° ì‹œì‘)
        }
    )
    
    # === ê³µí†µ ì¢…ë£Œ ì§€ì  ===
    # ê²°ê³¼ í†µí•©: SQL ê²½ë¡œì™€ Python ê²½ë¡œ ëª¨ë‘ ì—¬ê¸°ë¡œ ìˆ˜ë ´
    graph.add_edge("result_integration", "data_summarization")
    graph.add_edge("data_summarization", END)
    
    # Compile the graph with memory
    # Use provided checkpointer if available, otherwise create new one
    memory = checkpointer or MemorySaver()
    compiled_graph = graph.compile(checkpointer=memory)
    
    logger.info("LangGraph state machine created successfully")
    return compiled_graph


def _initialize_nodes(config: Dict[str, Any]) -> Dict[str, Any]:
    """Initialize all pipeline nodes."""
    logger.info("Initializing pipeline nodes")
    
    # Log config summary (without db_schema details to avoid cluttering logs)
    config_summary = {k: v for k, v in config.items() if k != "db_schema"}
    if "db_schema" in config:
        db_schema = config.get("db_schema", {})
        config_summary["db_schema"] = f"<{len(db_schema)} tables>"
    logger.debug(f"Config passed to _initialize_nodes: {config_summary}")
    
    # LLM ì„œë¹„ìŠ¤ë¥¼ configì— ì¶”ê°€
    from agentic_flow.llm_service import get_llm_service
    llm_service = get_llm_service()
    config["llm_service"] = llm_service
    
    nodes = {
        "llm_intent_classifier": LLMIntentClassifier(config),
        "nlp_processor": NLProcessor(config),
        # "schema_mapper": SchemaMapper(config),  # ì œê±°: RAGSchemaRetrieverNodeì— í†µí•©ë¨
        "rag_schema_retriever": RAGSchemaRetrieverNode(config),
        # DynamicSQLGenerator ì œê±° (SQLGenerationNodeì— í†µí•©ë¨)
        # "dynamic_sql_generator": DynamicSQLGenerator(config),
        "sql_generator": SQLGenerationNode(config),
        "sql_validator": SQLValidationNode(config),
        "validation_node": ValidationNode(),  # ë…ë¦½ì ìœ¼ë¡œ ì‘ë™, config ë¶ˆí•„ìš”
        "user_review_node": UserReviewNode(),  # ë…ë¦½ì ìœ¼ë¡œ ì‘ë™, config ë¶ˆí•„ìš”
        "python_code_generator": PythonCodeGeneratorNode(config),  # COMPLEX_ANALYSISìš© Python ì½”ë“œ ìƒì„±
        "code_executor": CodeExecutorNode(config),  # Python ì½”ë“œ ì‹¤í–‰ (ìƒŒë“œë°•ìŠ¤)
        "result_integrator": ResultIntegratorNode(config),  # SQL/Python ê²°ê³¼ í†µí•©
        "data_summarizer": DataSummarizationNode(config)
    }
    
    logger.info(f"Initialized {len(nodes)} pipeline nodes")
    return nodes


def _get_default_schema() -> Dict[str, Any]:
    """Get default database schema."""
    return {
        "t_member": {
            "description": "íšŒì› ì •ë³´ í…Œì´ë¸”",
            "columns": {
                "id": {"type": "int", "description": "íšŒì› ID"},
                "email": {"type": "varchar", "description": "ì´ë©”ì¼ ì£¼ì†Œ"},
                "nickname": {"type": "varchar", "description": "ë‹‰ë„¤ì„"},
                "status": {"type": "varchar", "description": "íšŒì› ìƒíƒœ"},
                "created_at": {"type": "timestamp", "description": "ê°€ì…ì¼"}
            }
        },
        "t_creator": {
            "description": "í¬ë¦¬ì—ì´í„° ì •ë³´ í…Œì´ë¸”",
            "columns": {
                "id": {"type": "int", "description": "í¬ë¦¬ì—ì´í„° ID"},
                "nickname": {"type": "varchar", "description": "í¬ë¦¬ì—ì´í„° ë‹‰ë„¤ì„"},
                "description": {"type": "text", "description": "í¬ë¦¬ì—ì´í„° ì†Œê°œ"},
                "category": {"type": "varchar", "description": "ì¹´í…Œê³ ë¦¬"}
            }
        },
        "t_funding": {
            "description": "í€ë”© í”„ë¡œì íŠ¸ í…Œì´ë¸”",
            "columns": {
                "id": {"type": "int", "description": "í”„ë¡œì íŠ¸ ID"},
                "title": {"type": "varchar", "description": "í”„ë¡œì íŠ¸ ì œëª©"},
                "goal_amount": {"type": "int", "description": "ëª©í‘œ ê¸ˆì•¡"},
                "current_amount": {"type": "int", "description": "í˜„ì¬ ëª¨ê¸ˆì•¡"},
                "status": {"type": "varchar", "description": "í”„ë¡œì íŠ¸ ìƒíƒœ"},
                "created_at": {"type": "timestamp", "description": "ìƒì„±ì¼"}
            }
        }
    }


def route_after_intent_classification(state: AgentState) -> str:
    """
    ì¸í…íŠ¸ ë¶„ë¥˜ í›„ ë¼ìš°íŒ… ê²°ì • (3ê°ˆë˜ ë¶„ê¸°: CHAT_PATH, SQL_PATH, PYTHON_PATH)
    
    Phase 2 ìµœì í™”: llm_intent_classificationì—ì„œ ë°”ë¡œ 3ê°œì˜ ëª…í™•í•œ ê²½ë¡œë¡œ ë¶„ê¸°
    
    ê²½ë¡œ:
    - CHAT_PATH: ë¹„ë°ì´í„° ì˜ë„ (GREETING, HELP_REQUEST, GENERAL_CHAT)
    - SQL_PATH: SIMPLE_AGGREGATION (Fast Path ì ìš©)
    - PYTHON_PATH: COMPLEX_ANALYSIS (Safe Path)
    
    Args:
        state: Current pipeline state
        
    Returns:
        Next node name ("CHAT_PATH", "SQL_PATH", "PYTHON_PATH")
    """
    from agentic_flow.state import QueryIntent
    
    llm_intent_result = state.get("llm_intent_result")
    conversation_response = state.get("conversation_response")
    skip_sql = state.get("skip_sql_generation", False)
    
    # ë¼ìš°íŒ… ê²°ì •ì„ debug_infoì— ê¸°ë¡
    if "debug_info" not in state:
        state["debug_info"] = {}
    if "routing_decisions" not in state["debug_info"]:
        state["debug_info"]["routing_decisions"] = {}
    
    # LLM ë¶„ë¥˜ ì‹¤íŒ¨ ì‹œ SQL_PATHë¡œ ì§„í–‰ (fallback, ì•ˆì „í•œ ê¸°ë³¸ê°’)
    if not llm_intent_result:
        logger.warning("LLM intent classification failed, defaulting to SQL_PATH for safety")
        state["debug_info"]["routing_decisions"]["intent_classification"] = {
            "decision": "SQL_PATH",
            "reason": "llm_classification_failed"
        }
        return "SQL_PATH"
    
    # ì¸í…íŠ¸ ì¶”ì¶œ
    intent_str = llm_intent_result.get("intent", "").upper()
    try:
        intent = QueryIntent(intent_str)
    except ValueError:
        logger.warning(f"Unknown intent: {intent_str}, defaulting to SQL_PATH for safety")
        state["debug_info"]["routing_decisions"]["intent_classification"] = {
            "decision": "SQL_PATH",
            "reason": "unknown_intent"
        }
        return "SQL_PATH"
    
    # CHAT_PATH: ë¹„ë°ì´í„° ì˜ë„ (ì¸ì‚¬/ë„ì›€ë§/ì¼ë°˜ ëŒ€í™”)
    # ìµœì í™”: nlp_processingì„ ê±´ë„ˆë›°ê³  ë°”ë¡œ data_summarizationìœ¼ë¡œ ì§í–‰
    # ì‘ë‹µ ìƒì„±ì€ data_summarization ë…¸ë“œì—ì„œ ìˆ˜í–‰ (ë´‡ ê¸°ëŠ¥ì— ë§ì¶˜ ì‘ë‹µ)
    # ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì‚¬ìš©
    if is_intent_in(intent, [QueryIntent.GREETING, QueryIntent.HELP_REQUEST, QueryIntent.GENERAL_CHAT]):
        logger.info(f"CHAT_PATH: Non-data intent ({intent.value}) detected, routing directly to data_summarization (skipping nlp_processing)")
        state["skip_sql_generation"] = True
        state["debug_info"]["routing_decisions"]["intent_classification"] = {
            "decision": "CHAT_PATH",
            "reason": f"non_data_intent_{intent.value}_direct_to_summarization",
            "intent": intent.value,
            "optimization": "skipped_nlp_processing",
            "note": "Response will be generated in data_summarization node with bot-specific information"
        }
        return "CHAT_PATH"
    
    # SQL_PATH: SIMPLE_AGGREGATION (Fast Path)
    # ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì‚¬ìš©
    elif is_intent_equal(intent, QueryIntent.SIMPLE_AGGREGATION):
        logger.info(f"SQL_PATH: SIMPLE_AGGREGATION detected, routing to SQL path")
        state["debug_info"]["routing_decisions"]["intent_classification"] = {
            "decision": "SQL_PATH",
            "reason": "simple_aggregation_intent",
            "intent": intent.value
        }
        return "SQL_PATH"
    
    # PYTHON_PATH: COMPLEX_ANALYSIS (Safe Path)
    # ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì‚¬ìš©
    elif is_intent_equal(intent, QueryIntent.COMPLEX_ANALYSIS):
        logger.info(f"PYTHON_PATH: COMPLEX_ANALYSIS detected, routing to Python path")
        state["debug_info"]["routing_decisions"]["intent_classification"] = {
            "decision": "PYTHON_PATH",
            "reason": "complex_analysis_intent",
            "intent": intent.value
        }
        return "PYTHON_PATH"
    
    # ê¸°íƒ€: SQL_PATHë¡œ ì§„í–‰ (fallback, ì•ˆì „í•œ ê¸°ë³¸ê°’)
    else:
        logger.warning(f"Unknown intent ({intent.value}), defaulting to SQL_PATH for safety")
        state["debug_info"]["routing_decisions"]["intent_classification"] = {
            "decision": "SQL_PATH",
            "reason": "unknown_intent_fallback",
            "intent": str(intent)
        }
        return "SQL_PATH"


def route_after_rag_retrieval(state: AgentState) -> str:
    """
    RAG ê²€ìƒ‰ í›„ ë¼ìš°íŒ… ê²°ì •
    
    Intentë¥¼ í™•ì¸í•˜ì—¬ ê²½ë¡œë³„ë¡œ ë¶„ê¸°:
    - COMPLEX_ANALYSIS: SQL ìƒì„± ê±´ë„ˆë›°ê³  ë°”ë¡œ python_code_generationìœ¼ë¡œ
    - SIMPLE_AGGREGATION: sql_generationìœ¼ë¡œ
    
    Args:
        state: Current pipeline state
        
    Returns:
        Next node name ("sql_generation" ë˜ëŠ” "python_code_generation")
    """
    from agentic_flow.state import QueryIntent
    
    intent = state.get("intent")
    rag_schema_chunks = state.get("rag_schema_chunks", [])
    rag_schema_context = state.get("rag_schema_context")
    
    # ë¼ìš°íŒ… ê²°ì •ì„ debug_infoì— ê¸°ë¡ (ë””ë²„ê¹… ëª©ì )
    if "debug_info" not in state:
        state["debug_info"] = {}
    if "routing_decisions" not in state["debug_info"]:
        state["debug_info"]["routing_decisions"] = {}
    
    # RAG ê²°ê³¼ í’ˆì§ˆ í‰ê°€ (ë””ë²„ê¹… ë° ë¡œê¹… ëª©ì )
    high_quality_chunks = [
        chunk for chunk in rag_schema_chunks
        if isinstance(chunk, dict) and chunk.get("relevance_score", 0.0) >= 0.5
    ]
    
    avg_relevance = 0.0
    if high_quality_chunks:
        avg_relevance = sum(
            chunk.get("relevance_score", 0.0) for chunk in high_quality_chunks
        ) / len(high_quality_chunks)
    
    # PYTHON_PATH: SQL ìƒì„± ê±´ë„ˆë›°ê³  ë°”ë¡œ python_code_generationìœ¼ë¡œ
    # ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì‚¬ìš©
    if is_intent_equal(intent, QueryIntent.COMPLEX_ANALYSIS):
        logger.info(
            f"PYTHON_PATH: Routing directly to python_code_generation "
            f"(skipping sql_generation, RAG chunks: {len(rag_schema_chunks)})"
        )
        decision = "python_code_generation"
        reason = "complex_analysis_intent_skip_sql_generation"
        
        # ë””ë²„ê¹… ì •ë³´ ê¸°ë¡
        state["debug_info"]["routing_decisions"]["rag_retrieval"] = {
            "decision": decision,
            "reason": reason,
            "intent": "COMPLEX_ANALYSIS",
            "chunks_count": len(rag_schema_chunks),
            "high_quality_chunks": len(high_quality_chunks),
            "avg_relevance": avg_relevance,
            "note": "SQL generation skipped for COMPLEX_ANALYSIS"
        }
        return decision
    
    # SQL_PATH: sql_generationìœ¼ë¡œ
    # ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì‚¬ìš©
    if is_intent_equal(intent, QueryIntent.SIMPLE_AGGREGATION):
        if rag_schema_chunks and rag_schema_context:
            logger.info(
                f"SQL_PATH: RAG results found ({len(rag_schema_chunks)} chunks, "
                f"avg relevance: {avg_relevance:.3f}), proceeding to SQL generation"
            )
            decision = "sql_generation"
            reason = "rag_results_available"
        else:
            logger.info("SQL_PATH: No RAG results found, proceeding to SQL generation (fallback)")
            decision = "sql_generation"
            reason = "no_rag_results"
        
        # ë””ë²„ê¹… ì •ë³´ ê¸°ë¡
        state["debug_info"]["routing_decisions"]["rag_retrieval"] = {
            "decision": decision,
            "reason": reason,
            "intent": "SIMPLE_AGGREGATION",
            "chunks_count": len(rag_schema_chunks),
            "high_quality_chunks": len(high_quality_chunks),
            "avg_relevance": avg_relevance,
            "note": "Proceeding to SQL generation"
        }
        return decision
    
    # ê¸°íƒ€/ì•Œ ìˆ˜ ì—†ìŒ: ê¸°ë³¸ì ìœ¼ë¡œ SQL ê²½ë¡œë¡œ ì§„í–‰ (ì•ˆì „)
    logger.warning(f"Unknown intent ({intent}) after RAG retrieval, defaulting to SQL generation path")
    decision = "sql_generation"
    reason = "unknown_intent_fallback"
    
    # ë””ë²„ê¹… ì •ë³´ ê¸°ë¡
    state["debug_info"]["routing_decisions"]["rag_retrieval"] = {
        "decision": decision,
        "reason": reason,
        "intent": str(intent),
        "chunks_count": len(rag_schema_chunks),
        "high_quality_chunks": len(high_quality_chunks),
        "avg_relevance": avg_relevance,
        "note": "Unknown intent, defaulting to SQL generation"
    }
    
    return decision


def route_after_nlp_processing(state: AgentState) -> str:
    """
    NLP ì²˜ë¦¬ í›„ ê²½ë¡œ ë¶„ê¸° ê²°ì • (ë°ì´í„° ê²½ë¡œë§Œ ì²˜ë¦¬)
    
    ìµœì í™”: CHAT_PATHëŠ” ì´ë¯¸ llm_intent_classificationì—ì„œ ë°”ë¡œ data_summarizationìœ¼ë¡œ ë¼ìš°íŒ…ë˜ì—ˆìœ¼ë¯€ë¡œ,
    ì´ í•¨ìˆ˜ëŠ” SQL_PATHì™€ PYTHON_PATHë§Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    
    schema_mapping ë…¸ë“œ ì œê±°, rag_schema_retrievalë¡œ ì§ì ‘ ë¼ìš°íŒ…
    
    Args:
        state: Current pipeline state
        
    Returns:
        Next node name ("rag_schema_retrieval" or "end")
    """
    from agentic_flow.state import QueryIntent
    
    # ì¬ì…ë ¥ ìš”ì²­ì´ í•„ìš”í•œ ê²½ìš° ì¡°ê¸° ì¢…ë£Œ
    if state.get("needs_clarification", False):
        logger.info("Clarification needed, ending pipeline early")
        return "end"
    
    # ì˜ë„ í™•ì¸ (NLP processingì—ì„œ ì„¤ì •ë¨)
    intent = state.get("intent")
    
    # ë¼ìš°íŒ… ê²°ì •ì„ debug_infoì— ê¸°ë¡
    if "debug_info" not in state:
        state["debug_info"] = {}
    if "routing_decisions" not in state["debug_info"]:
        state["debug_info"]["routing_decisions"] = {}
    
    # SQL_PATH: SIMPLE_AGGREGATION (Fast Path)
    # ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì‚¬ìš©
    if is_intent_equal(intent, QueryIntent.SIMPLE_AGGREGATION):
        logger.info("SQL_PATH: SIMPLE_AGGREGATION detected, routing to rag_schema_retrieval (schema_mapping integrated)")
        state["debug_info"]["routing_decisions"]["nlp_processing"] = {
            "decision": "SQL_PATH",
            "intent": "SIMPLE_AGGREGATION",
            "reason": "simple_aggregation_intent",
            "next_node": "rag_schema_retrieval",
            "note": "schema_mapping functionality integrated into rag_schema_retrieval"
        }
        return "SQL_PATH"
    
    # PYTHON_PATH: COMPLEX_ANALYSIS (Safe Path)
    # ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì‚¬ìš©
    elif is_intent_equal(intent, QueryIntent.COMPLEX_ANALYSIS):
        logger.info("PYTHON_PATH: COMPLEX_ANALYSIS detected, routing to rag_schema_retrieval (schema_mapping integrated)")
        state["debug_info"]["routing_decisions"]["nlp_processing"] = {
            "decision": "PYTHON_PATH",
            "intent": "COMPLEX_ANALYSIS",
            "reason": "complex_analysis_intent",
            "next_node": "rag_schema_retrieval",
            "note": "schema_mapping functionality integrated into rag_schema_retrieval"
        }
        return "PYTHON_PATH"  # Python ê²½ë¡œë„ ìŠ¤í‚¤ë§ˆ ì •ë³´ê°€ í•„ìš”í•˜ë¯€ë¡œ rag_schema_retrievalë¡œ ë¼ìš°íŒ…
    
    # CHAT_PATHëŠ” ì—¬ê¸°ì— ë„ë‹¬í•˜ì§€ ì•Šì•„ì•¼ í•¨ (ì´ë¯¸ llm_intent_classificationì—ì„œ ì²˜ë¦¬ë¨)
    # í•˜ì§€ë§Œ í˜¹ì‹œ ëª¨ë¥¼ ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ fallback
    # ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì‚¬ìš©
    elif is_intent_in(intent, [QueryIntent.GREETING, QueryIntent.HELP_REQUEST, QueryIntent.GENERAL_CHAT]):
        logger.warning(f"CHAT_PATH reached nlp_processing (unexpected), this should have been handled earlier")
        # ì´ë¯¸ llm_intent_classificationì—ì„œ ì²˜ë¦¬ë˜ì—ˆì–´ì•¼ í•˜ëŠ”ë° ì—¬ê¸° ë„ë‹¬í–ˆë‹¤ë©´ ì˜¤ë¥˜
        # í•˜ì§€ë§Œ ì•ˆì „ì„ ìœ„í•´ ì¡°ê¸° ì¢…ë£Œ
        return "end"
    
    # ê¸°íƒ€/ì•Œ ìˆ˜ ì—†ìŒ: ê¸°ë³¸ì ìœ¼ë¡œ SQL ê²½ë¡œë¡œ ì§„í–‰ (í•˜ìœ„ í˜¸í™˜ì„±)
    else:
        logger.warning(f"Unknown or unclear intent ({intent}), defaulting to SQL_PATH for safety")
        state["debug_info"]["routing_decisions"]["nlp_processing"] = {
            "decision": "SQL_PATH",
            "intent": str(intent),
            "reason": "unknown_intent_fallback"
        }
        return "SQL_PATH"


def route_after_validation(state: AgentState) -> str:
    """
    Route after SQL validation based on validation result and retry count.
    
    Phase 1 ìµœì í™”: SIMPLE_AGGREGATION ê²½ë¡œ Fast Path êµ¬í˜„
    - ê²€ì¦ í†µê³¼ ì‹œ validation_check ê±´ë„ˆë›°ê³  ë°”ë¡œ sql_executionìœ¼ë¡œ ì´ë™
    
    Args:
        state: Current pipeline state
        
    Returns:
        Next node name ("retry", "validate", "sql_execution")
    """
    from agentic_flow.state import QueryIntent
    
    validation_result = state.get("validation_result", {})
    retry_count = state.get("retry_count", 0)
    max_retries = state.get("max_retries", 3)
    intent = state.get("intent")
    
    # Check if this is a conversation response (greeting, help, etc.)
    # ë‹¨, SQLì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìœ¼ë©´ conversation_responseë¥¼ ë¬´ì‹œí•˜ê³  SQL ì‹¤í–‰
    conversation_response = state.get("conversation_response")
    sql_query = state.get("sql_query")
    dynamic_sql_result = state.get("dynamic_sql_result", {})
    has_valid_sql = (
        sql_query or 
        (isinstance(dynamic_sql_result, dict) and dynamic_sql_result.get("sql_query"))
    )
    
    if conversation_response and not has_valid_sql:
        # SQLì´ ì—†ê³  conversation_responseë§Œ ìˆëŠ” ê²½ìš° (GREETING, HELP_REQUEST ë“±)
        logger.info("Conversation response detected (no SQL), skipping validation and proceeding to execution")
        return "sql_execution"
    elif conversation_response and has_valid_sql:
        # SQLì´ ìƒì„±ë˜ì—ˆëŠ”ë° conversation_responseë„ ìˆëŠ” ê²½ìš° (clarificationì´ ìˆì—ˆì§€ë§Œ SQL ìƒì„± ì„±ê³µ)
        logger.info("SQL successfully generated despite previous clarification request, clearing conversation_response and proceeding with SQL execution")
        state["conversation_response"] = None
        state["needs_clarification"] = False
    
    # SIMPLE_AGGREGATION Fast Path ê°•í™”
    # ê²€ì¦ í†µê³¼ ì‹œ validation_check ê±´ë„ˆë›°ê³  ë°”ë¡œ ì‹¤í–‰ (ì„ê³„ê°’ ë‚®ì¶¤)
    # ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì‚¬ìš©
    if is_intent_equal(intent, QueryIntent.SIMPLE_AGGREGATION):
        if validation_result and validation_result.get("is_valid", False):
            confidence = validation_result.get("confidence", 0.0)
            
            # Fast Path ì„ê³„ê°’ì„ 0.5ë¡œ ë‚®ì¶¤ (ë” ë§ì€ ì¿¼ë¦¬ê°€ ë¹ ë¥¸ ê²½ë¡œë¡œ ì²˜ë¦¬ë¨)
            # ê°„ë‹¨í•œ ì§‘ê³„ ì¿¼ë¦¬ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ë¹ ë¥¸ ê²½ë¡œë¡œ ì²˜ë¦¬
            if confidence >= 0.5:
                logger.info(
                    f"SIMPLE_AGGREGATION Fast Path: Validation passed "
                    f"(confidence: {confidence:.2f}), executing immediately"
                )
                return "sql_execution"
            
            # ë§¤ìš° ë‚®ì€ ì‹ ë¢°ë„ë§Œ validation_checkë¡œ ì´ë™ (ì•ˆì „ì¥ì¹˜)
            logger.warning(
                f"SIMPLE_AGGREGATION: Very low confidence ({confidence:.2f}), "
                f"proceeding to validation check for review"
            )
            return "validate"
    
    # ê¸°íƒ€ ì˜ë„ ë˜ëŠ” SIMPLE_AGGREGATION ê²€ì¦ ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ë¡œì§
    # Check if validation passed
    if validation_result and validation_result.get("is_valid", False):
        logger.info("SQL validation passed, proceeding to validation check")
        return "validate"
    
    # Check retry count
    if retry_count < max_retries:
        logger.warning(f"SQL validation failed, retrying ({retry_count + 1}/{max_retries})")
        # ì¬ì‹œë„ ì¹´ìš´íŠ¸ ì¦ê°€
        state["retry_count"] = retry_count + 1
        return "retry"
    else:
        logger.warning("Max retries exceeded, proceeding to validation check for final decision")
        # ì¬ì‹œë„ ì¹´ìš´íŠ¸ ì´ˆê¸°í™”í•˜ê³  validation_checkì—ì„œ ìµœì¢… ê²°ì •
        state["retry_count"] = 0
        return "validate"


def route_after_validation_check(state: AgentState) -> str:
    """
    ê²€ì¦ ì²´í¬ í›„ ë¼ìš°íŒ… ê²°ì •
    
    SIMPLE_AGGREGATION ì¿¼ë¦¬ì— ëŒ€í•´ì„œëŠ” ê°„ì†Œí™”ëœ ê²½ë¡œ ì ìš©:
    - ë†’ì€ ì‹ ë¢°ë„ ë˜ëŠ” ê¸°ë³¸ ê²€ì¦ í†µê³¼ ì‹œ ìë™ ìŠ¹ì¸
    - UserReviewNode ê±´ë„ˆë›°ê³  ì§ì ‘ SQL ì‹¤í–‰
    
    Args:
        state: Current pipeline state
        
    Returns:
        str: ë‹¤ìŒ ë…¸ë“œ ì´ë¦„ ("sql_execution", "user_review", "reject")
    """
    from agentic_flow.state import QueryIntent
    
    validation_result = state.get("validation_result")
    processing_decision = state.get("processing_decision") or {}
    intent = state.get("intent")
    
    # SIMPLE_AGGREGATION ì¿¼ë¦¬ ê°„ì†Œí™” ì²˜ë¦¬ ê°•í™”
    # ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì‚¬ìš©
    if is_intent_equal(intent, QueryIntent.SIMPLE_AGGREGATION):
        if not validation_result:
            logger.info("SIMPLE_AGGREGATION: No validation result, auto-approving")
            return "sql_execution"
        
        # ê¸°ë³¸ SQL êµ¬ë¬¸ ê²€ì¦ í†µê³¼ ì‹œ ìë™ ìŠ¹ì¸
        if isinstance(validation_result, dict):
            is_valid = validation_result.get("is_valid", False)
            confidence = validation_result.get("confidence", 0)
            
            # Fast Path ì„ê³„ê°’ì„ 0.5ë¡œ ë‚®ì¶¤ (ë” ë§ì€ ì¿¼ë¦¬ê°€ ìë™ ìŠ¹ì¸ë¨)
            # ê°„ë‹¨í•œ ì§‘ê³„ ì¿¼ë¦¬ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ìë™ ìŠ¹ì¸
            if is_valid and confidence >= 0.5:
                logger.info(
                    f"SIMPLE_AGGREGATION: Auto-approving simple query "
                    f"(confidence: {confidence:.2f}, valid: {is_valid})"
                )
                return "sql_execution"
            
            # ë§¤ìš° ë‚®ì€ ì‹ ë¢°ë„ë§Œ ì‚¬ìš©ì ê²€í†  (ì„ê³„ê°’ 0.5 ë¯¸ë§Œ)
            if confidence < 0.5:
                logger.warning(
                    f"SIMPLE_AGGREGATION: Very low confidence ({confidence:.2f}), "
                    f"requiring user review"
                )
                return "user_review"
            
            # ê²€ì¦ ì‹¤íŒ¨ ì‹œì—ë„ ì¤‘ê°„ ì‹ ë¢°ë„ë©´ ìë™ ìŠ¹ì¸ (ê°„ì†Œí™”)
            logger.info(
                f"SIMPLE_AGGREGATION: Auto-approving with intermediate confidence "
                f"({confidence:.2f}) despite validation status"
            )
            return "sql_execution"
    
    # COMPLEX_ANALYSIS ë° ê¸°íƒ€ ì¿¼ë¦¬ëŠ” ê¸°ì¡´ ë¡œì§ ìœ ì§€
    if not validation_result:
        logger.warning("No validation result found, defaulting to user review")
        return "user_review"
    
    # ìë™ ìŠ¹ì¸ ì¡°ê±´ í™•ì¸ (ë†’ì€ ì‹ ë¢°ë„)
    if processing_decision and processing_decision.get("auto_approve", False):
        logger.info("Auto-approving query based on high confidence")
        return "sql_execution"
    
    # ë†’ì€ ì‹ ë¢°ë„ë©´ ìë™ ìŠ¹ì¸
    if isinstance(validation_result, dict) and validation_result.get("confidence", 0) >= 0.85:
        confidence = validation_result.get("confidence", 0)
        logger.info(f"High confidence ({confidence:.2f}), auto-approving")
        return "sql_execution"
    
    # ì¬ì‹œë„ íšŸìˆ˜ ì²´í¬ (ë¬´í•œ ë£¨í”„ ë°©ì§€)
    retry_count = state.get("retry_count", 0)
    max_retries = state.get("max_retries", 3)
    
    if retry_count >= max_retries:
        logger.error(f"Max retries ({max_retries}) exceeded, rejecting query")
        return "reject"
    
    # ê²€ì¦ ì‹¤íŒ¨ ì‹œ ì‚¬ìš©ì ê²€í† ë¡œ ì´ë™ (ê°•ì œ ì‹¤í–‰ ì œê±°)
    if isinstance(validation_result, dict):
        status_value = validation_result.get("status")
        if status_value and (hasattr(status_value, "value") and status_value.value == "rejected" or status_value == "rejected"):
            logger.warning("Query rejected due to validation issues, requiring user review")
            return "user_review"
    
    # ì‚¬ìš©ì ê²€í†  í•„ìš” ì¡°ê±´ í™•ì¸
    if processing_decision and processing_decision.get("needs_user_review", False):
        logger.info("Query requires user review")
        return "user_review"
    
    # ê¸°ë³¸ì ìœ¼ë¡œ ì‚¬ìš©ì ê²€í† ë¡œ ì´ë™
    logger.info("Defaulting to user review for safety")
    return "user_review"


def route_after_sql_generation(state: AgentState) -> str:
    """
    SQL ìƒì„± í›„ ë¼ìš°íŒ… ê²°ì •
    
    ì£¼ì˜: ì´ í•¨ìˆ˜ëŠ” SQL_PATH (SIMPLE_AGGREGATION)ì—ì„œë§Œ í˜¸ì¶œë©ë‹ˆë‹¤.
    PYTHON_PATH (COMPLEX_ANALYSIS)ëŠ” ì´ë¯¸ rag_schema_retrievalì—ì„œ python_code_generationìœ¼ë¡œ ë¼ìš°íŒ…ë˜ì—ˆìŠµë‹ˆë‹¤.
    
    Args:
        state: Current pipeline state
        
    Returns:
        str: ë‹¤ìŒ ë…¸ë“œ ì´ë¦„ ("sql_validation")
    """
    from agentic_flow.state import QueryIntent
    
    intent = state.get("intent")
    
    # SQL_PATH: ê²€ì¦ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ (Fast Path)
    # ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì‚¬ìš©
    if is_intent_equal(intent, QueryIntent.SIMPLE_AGGREGATION):
        logger.info("SQL_PATH: Routing to SQL validation (Fast Path)")
        return "sql_validation"
    
    # COMPLEX_ANALYSISê°€ ì—¬ê¸°ì— ë„ë‹¬í•˜ë©´ ì•ˆ ë¨ (ì´ë¯¸ rag_schema_retrievalì—ì„œ ì²˜ë¦¬ë¨)
    # í•˜ì§€ë§Œ í˜¹ì‹œ ëª¨ë¥¼ ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ fallback
    if is_intent_equal(intent, QueryIntent.COMPLEX_ANALYSIS):
        logger.warning("COMPLEX_ANALYSIS reached route_after_sql_generation (unexpected), this should have been handled earlier")
        # ì•ˆì „ì„ ìœ„í•´ python_code_generationìœ¼ë¡œ ë¼ìš°íŒ… (í•˜ì§€ë§Œ ì¼ë°˜ì ìœ¼ë¡œ ë°œìƒí•˜ì§€ ì•Šì•„ì•¼ í•¨)
        return "python_code_generation"
    
    # ê¸°íƒ€: ê¸°ë³¸ì ìœ¼ë¡œ SQL ê²€ì¦ ê²½ë¡œ (ì•ˆì „)
    logger.info(f"Unknown intent ({intent}), defaulting to SQL validation path")
    return "sql_validation"


def route_after_sql_execution(state: AgentState) -> str:
    """
    SQL ì‹¤í–‰ í›„ ë¼ìš°íŒ… ê²°ì • (SQL_PATH vs PYTHON_PATH ë¶„ê¸°)
    
    SQL_PATH (SIMPLE_AGGREGATION): result_integrationìœ¼ë¡œ
    PYTHON_PATH (COMPLEX_ANALYSIS): code_executionìœ¼ë¡œ
    
    Args:
        state: Current pipeline state
        
    Returns:
        str: ë‹¤ìŒ ë…¸ë“œ ì´ë¦„ ("result_integration" ë˜ëŠ” "code_execution")
    """
    from agentic_flow.state import QueryIntent
    
    intent = state.get("intent")
    
    # PYTHON_PATH: Python ì½”ë“œ ì‹¤í–‰ í•„ìš”
    # ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì‚¬ìš©
    if is_intent_equal(intent, QueryIntent.COMPLEX_ANALYSIS):
        # python_codeê°€ ìˆìœ¼ë©´ code_executionìœ¼ë¡œ
        if state.get("python_code"):
            logger.info("PYTHON_PATH: Routing to code_execution after SQL execution")
            return "code_execution"
        else:
            logger.warning("PYTHON_PATH: No python_code found, routing to result_integration")
            return "result_integration"
    
    # SQL_PATH: ê²°ê³¼ í†µí•©ìœ¼ë¡œ
    logger.info("SQL_PATH: Routing to result_integration after SQL execution")
    return "result_integration"


def route_after_code_execution(state: AgentState) -> str:
    """
    Python ì½”ë“œ ì‹¤í–‰ í›„ ë¼ìš°íŒ… ê²°ì • (ë‹¨ìˆœí™”ë¨)
    
    ì„±ê³µ ì‹œ ë°”ë¡œ ê²°ê³¼ í†µí•©, ì‹¤íŒ¨ ì‹œ SQL ê²½ë¡œë¡œ í´ë°±
    
    Args:
        state: Current pipeline state
        
    Returns:
        str: ë‹¤ìŒ ë…¸ë“œ ì´ë¦„ ("result_integration" ë˜ëŠ” "sql_validation")
    """
    python_execution_result = state.get("python_execution_result")
    
    if python_execution_result and python_execution_result.get("success"):
        # Python ì‹¤í–‰ ì„±ê³µ: ë°”ë¡œ ê²°ê³¼ í†µí•©
        logger.info("Python execution successful, proceeding to result integration")
        return "result_integration"
    else:
        # Python ì‹¤í–‰ ì‹¤íŒ¨: SQL ê²½ë¡œë¡œ í´ë°± (ê²€ì¦ë¶€í„° ì‹œì‘)
        logger.warning("Python execution failed, falling back to SQL validation path")
        error_msg = python_execution_result.get("error_message", "Unknown error") if python_execution_result else "Execution failed"
        logger.info(f"Python execution error: {error_msg}, switching to SQL validation path")
        return "sql_validation"


def route_after_user_review(state: AgentState) -> str:
    """
    ì‚¬ìš©ì ê²€í†  í›„ ë¼ìš°íŒ… ê²°ì •
    
    Args:
        state: Current pipeline state
        
    Returns:
        str: ë‹¤ìŒ ë…¸ë“œ ì´ë¦„
    """
    review_status = state.get("review_status")
    review_result = state.get("review_result")
    
    # ìë™ ìŠ¹ì¸ëœ ê²½ìš° ì²˜ë¦¬
    if review_status == ReviewStatus.AUTO_APPROVED:
        logger.info("Query auto-approved, proceeding to execution")
        return "sql_execution"
    
    # PENDING ìƒíƒœì¸ ê²½ìš° ì‚¬ìš©ì ì‘ë‹µ ëŒ€ê¸° (ë¬´í•œ ë£¨í”„ ë°©ì§€)
    if review_status == ReviewStatus.PENDING:
        logger.info("Review pending, waiting for user response. Ending graph execution.")
        return "pending"
    
    # ì‚¬ìš©ì ê²€í†  ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš°
    if review_result and hasattr(review_result, 'status'):
        if review_result.status == ReviewStatus.APPROVED:
            logger.info("User approved query, proceeding to execution")
            return "sql_execution"
        elif review_result.status == ReviewStatus.REJECTED:
            logger.info("User rejected query, starting over")
            return "reject"
        elif review_result.status == ReviewStatus.MODIFIED:
            logger.info("User modified query, regenerating SQL")
            return "modify"
    
    # review_statusê°€ ìˆëŠ” ê²½ìš°
    if review_status:
        if review_status == ReviewStatus.APPROVED:
            logger.info("User approved query, proceeding to execution")
            return "sql_execution"
        elif review_status == ReviewStatus.REJECTED:
            logger.info("User rejected query, starting over")
            return "reject"
        elif review_status == ReviewStatus.MODIFIED:
            logger.info("User modified query, regenerating SQL")
            return "modify"
    
    # ê¸°ë³¸ê°’: ëª…í™•í•˜ì§€ ì•Šì€ ìƒíƒœì—ì„œëŠ” ì•ˆì „ì„ ìœ„í•´ ê±°ë¶€
    logger.warning("No clear review status found, defaulting to reject for safety")
    return "reject"


def _execute_sql_query_simple(state: AgentState) -> AgentState:
    """
    ê°„ë‹¨í•œ SQL ì‹¤í–‰ (Python ê²½ë¡œìš©, ë°ì´í„° ì¶”ì¶œ ì „ìš©)
    
    ë³µì¡í•œ ê²€ì¦ ì—†ì´ ê¸°ë³¸ êµ¬ë¬¸/ë³´ì•ˆ ê²€ì‚¬ë§Œ ìˆ˜í–‰í•˜ê³  ë°”ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.
    Python ì½”ë“œ ì‹¤í–‰ì„ ìœ„í•œ ë°ì´í„° ì¶”ì¶œì´ ëª©ì ì´ë¯€ë¡œ, 
    validation_check, user_review ë“±ì€ ìƒëµí•©ë‹ˆë‹¤.
    
    Args:
        state: Current pipeline state
        
    Returns:
        Updated state with query results
    """
    logger.info("Executing SQL query (simple mode for Python path)")
    
    start_time = time.time()
    state["current_node"] = "simple_sql_execution"
    state["execution_status"] = ExecutionStatus.IN_PROGRESS.value
    
    try:
        sql_query = state.get("sql_query")
        if not sql_query:
            raise ValueError("No SQL query to execute")
        
        # ê°„ë‹¨í•œ êµ¬ë¬¸ ê²€ì‚¬ë§Œ (ë³µì¡í•œ ê²€ì¦ ìƒëµ)
        # SQL ì£¼ì… ë°©ì§€ë¥¼ ìœ„í•œ ê¸°ë³¸ì ì¸ ê²€ì‚¬ë§Œ ìˆ˜í–‰
        dangerous_keywords = ["DROP", "DELETE", "TRUNCATE", "ALTER", "CREATE", "GRANT", "REVOKE"]
        sql_upper = sql_query.upper()
        
        for keyword in dangerous_keywords:
            if keyword in sql_upper:
                raise ValueError(f"Dangerous SQL keyword detected: {keyword}")
        
        # SQL íŒŒë¼ë¯¸í„° ê°€ì ¸ì˜¤ê¸° (SQL Injection ë°©ì§€)
        sql_params = state.get("sql_params")
        
        # Execute the query with parameters (if available)
        result = execute_query(sql_query, params=sql_params, readonly=True)
        execution_time = time.time() - start_time
        
        # Handle different return types
        if isinstance(result, int):
            query_result: List[Dict[str, Any]] = []
            logger.info(f"Query executed successfully (affected rows: {result})")
        else:
            query_result = result if isinstance(result, list) else []
            if result is None:
                logger.warning("SQL query returned None, treating as empty result")
        
        # Update state
        state["query_result"] = query_result
        state["execution_time"] = execution_time
        state["success"] = True
        state["execution_status"] = ExecutionStatus.COMPLETED.value
        
        logger.info(f"Simple SQL execution completed in {execution_time:.2f}s, returned {len(query_result)} rows")
        
    except Exception as e:
        execution_time = time.time() - start_time
        error_msg = f"Simple SQL execution failed: {str(e)}"
        
        logger.error(error_msg)
        
        # Update state with error
        state["error_message"] = error_msg
        state["success"] = False
        state["execution_status"] = ExecutionStatus.FAILED.value
    
    return state


def _execute_sql_query(state: AgentState) -> AgentState:
    """
    Execute the validated SQL query.
    
    Phase 2: Python ê²½ë¡œì˜ data_gathering_sqlë„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    
    Args:
        state: Current pipeline state
        
    Returns:
        Updated state with query results
    """
    from agentic_flow.state import QueryIntent
    
    intent = state.get("intent")
    
    # Python ê²½ë¡œ: data_gathering_sql ì‚¬ìš©
    # ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì‚¬ìš©
    if is_intent_equal(intent, QueryIntent.COMPLEX_ANALYSIS):
        data_gathering_sql = state.get("data_gathering_sql")
        if data_gathering_sql:
            logger.info(f"PYTHON_PATH: Executing data_gathering_sql for Python code")
            state["sql_query"] = data_gathering_sql  # sql_executionì´ ì‚¬ìš©í•˜ë„ë¡ ì„¤ì •
        else:
            logger.warning("PYTHON_PATH: data_gathering_sql not found, using sql_query")
    
    logger.info("Executing SQL query")
    
    start_time = time.time()
    state["current_node"] = "sql_execution"
    state["execution_status"] = ExecutionStatus.IN_PROGRESS.value
    
    try:
        # ì¼ë°˜ ëŒ€í™”ì¸ ê²½ìš° SQL ì‹¤í–‰ ê±´ë„ˆë›°ê¸°
        if state.get("skip_sql_generation", False):
            logger.info("Skipping SQL execution for conversational query")
            state["query_result"] = []
            state["success"] = True
            state["execution_time"] = 0.0
            state["execution_status"] = ExecutionStatus.COMPLETED.value
            return state
        
        sql_query = state.get("validated_sql") or state.get("sql_query")
        if not sql_query:
            raise ValueError("No SQL query to execute")
        
        # SQL íŒŒë¼ë¯¸í„° ê°€ì ¸ì˜¤ê¸° (SQL Injection ë°©ì§€)
        sql_params = state.get("sql_params")
        
        # Execute the query with parameters (if available)
        result = execute_query(sql_query, params=sql_params, readonly=True)
        execution_time = time.time() - start_time
        
        # Handle different return types: int (affected rows) or List[Dict[str, Any]] (query results)
        if isinstance(result, int):
            # For non-SELECT queries, convert to empty list
            query_result: List[Dict[str, Any]] = []
            logger.info(f"Query executed successfully (affected rows: {result})")
        else:
            # For SELECT queries, ensure result is a list
            query_result = result if isinstance(result, list) else []
            if result is None:
                logger.warning("SQL query returned None, treating as empty result")
        
        # Update state
        state["query_result"] = query_result
        state["execution_time"] = execution_time
        state["success"] = True
        state["execution_status"] = ExecutionStatus.COMPLETED.value
        
        # Record node execution result
        node_result = NodeExecutionResult(
            node_type=NodeType.SQL_EXECUTION,
            success=True,
            execution_time=execution_time,
            confidence=1.0,
            metadata={"rows_returned": len(query_result)}
        )
        state["node_results"].append(node_result)
        
        logger.info(f"Query executed successfully in {execution_time:.2f}s, returned {len(query_result)} rows")
        
    except Exception as e:
        execution_time = time.time() - start_time
        error_msg = f"SQL execution failed: {str(e)}"
        
        logger.error(error_msg)
        
        # Update state with error
        state["error_message"] = error_msg
        state["success"] = False
        state["execution_status"] = ExecutionStatus.FAILED.value
        
        # Record node execution result
        node_result = NodeExecutionResult(
            node_type=NodeType.SQL_EXECUTION,
            success=False,
            execution_time=execution_time,
            confidence=0.0,
            error_message=error_msg
        )
        state["node_results"].append(node_result)
    
    return state


def initialize_state(
    user_query: str,
    user_id: Optional[str] = None,
    channel_id: Optional[str] = None,
    session_id: Optional[str] = None,
    context: Optional[Dict[str, Any]] = None,
    max_retries: int = 3,
    conversation_history: Optional[List[Dict[str, str]]] = None
) -> AgentState:
    """
    Initialize the pipeline state.
    
    Args:
        user_query: User's natural language query
        user_id: User identifier
        channel_id: Channel identifier
        session_id: Session identifier
        context: Additional context
        max_retries: Maximum number of retries
        conversation_history: Previous conversation history for context awareness
        
    Returns:
        Initialized AgentState
    """
    return AgentState(
        # Input
        user_query=user_query,
        user_id=user_id,
        channel_id=channel_id,
        session_id=session_id,
        context=context or {},
        
        # Processing stages
        normalized_query=None,
        intent=None,
        llm_intent_result=None,
        entities=[],
        agent_schema_mapping=None,
        sql_query=None,
        validated_sql=None,
        query_result=[],
        data_summary=None,
        
        # Conversation handling
        skip_sql_generation=False,
        conversation_response=None,
        needs_clarification=None,
        
        # Fanding templates
        fanding_template=None,
        
        # Validation and error handling
        validation_result=None,
        processing_decision=None,
        is_valid=True,
        error_message=None,
        retry_count=0,
        max_retries=max_retries,
        
        # Execution tracking
        current_node=None,
        execution_status=ExecutionStatus.PENDING.value,
        node_results=[],
        
        # Metadata
        processing_time=0.0,
        execution_time=0.0,
        confidence_scores={},
        debug_info={},
        
        # RAG schema retrieval
        rag_schema_chunks=None,
        rag_schema_context=None,
        
        # Conversation history
        conversation_history=conversation_history or [],
        
        # Additional fields for review
        review_status=None,
        review_result=None,
        
        # Output
        final_sql=None,
        explanation=None,
        success=False
    )
