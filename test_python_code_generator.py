import json
import re
from typing import TypedDict, List, Dict, Any

from langgraph.graph import StateGraph, END
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser, JsonOutputParser
from test_config import (
    llm,
    STATE,
    save_result,
    run_dynamic_code,
    PROMPT_SEARCH_RELATIVE_TABLES,
    PROMPT_GENERATE_SQL_QUERY,
    PROMPT_VALIDATE_SQL_QUERY,
    PROMPT_GENERATE_FINAL_RESULT,
    PROMPT_PLAN_PYTHON_ANALYSIS,
    PROMPT_GENERATE_PYTHON_STEP,
    PROMPT_VALIDATE_PYTHON_STEP,
)
from rule_rag import retrieve_relevant_rules


def summarize_context_for_llm(context: Dict[str, Any]) -> str:
    """Create a meaningful summary of python context for the LLM."""
    summary_lines = []
    
    for var_name, value in context.items():
        if var_name == "__builtins__":
            continue
        
        # í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ì •ë³´ íŠ¹ë³„ ì²˜ë¦¬
        if var_name == "_table_schemas":
            summary_lines.append("\n=== ğŸ“‹ í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ì •ë³´ (SQL ì‘ì„± ì‹œ ë°˜ë“œì‹œ ì°¸ì¡°) ===")
            for table_info in value:
                table_name = table_info.get("table", "unknown")
                schema = table_info.get("schema", [])
                summary_lines.append(f"  â€¢ {table_name}:")
                for col in schema:
                    col_name = col.get("column", "unknown")
                    col_type = col.get("type", "")
                    summary_lines.append(f"    - {col_name} ({col_type})")
            summary_lines.append("=== (ìŠ¤í‚¤ë§ˆì— ì—†ëŠ” ì»¬ëŸ¼ ì‚¬ìš© ê¸ˆì§€!) ===\n")
            continue
            
        type_name = type(value).__name__
        
        # DataFrameì¸ ê²½ìš°
        if hasattr(value, 'shape') and hasattr(value, 'columns'):
            columns_list = list(value.columns)
            columns_preview = columns_list[:10]  # ì²˜ìŒ 10ê°œ ì»¬ëŸ¼ë§Œ
            if len(columns_list) > 10:
                columns_preview_str = f"{columns_preview}... (ì´ {len(columns_list)}ê°œ ì»¬ëŸ¼)"
            else:
                columns_preview_str = str(columns_list)
            summary_lines.append(
                f"- `{var_name}`: DataFrame, shape={value.shape}, columns={columns_preview_str}"
            )
        # List/Tupleì¸ ê²½ìš°
        elif isinstance(value, (list, tuple)):
            if len(value) > 0:
                first_item_type = type(value[0]).__name__
                summary_lines.append(
                    f"- `{var_name}`: {type_name}, length={len(value)}, first_item_type={first_item_type}"
                )
            else:
                summary_lines.append(
                    f"- `{var_name}`: {type_name}, length=0 (empty)"
                )
        # Dictì¸ ê²½ìš°
        elif isinstance(value, dict):
            keys_preview = list(value.keys())[:5]
            if len(value) > 5:
                summary_lines.append(
                    f"- `{var_name}`: {type_name}, keys={keys_preview}... (ì´ {len(value)}ê°œ)"
                )
            else:
                summary_lines.append(
                    f"- `{var_name}`: {type_name}, keys={list(value.keys())}"
                )
        # Stringì¸ ê²½ìš°
        elif isinstance(value, str):
            preview = value[:100] + "..." if len(value) > 100 else value
            summary_lines.append(
                f"- `{var_name}`: {type_name}, value='{preview}'"
            )
        # ìˆ«ì/ê¸°ë³¸ íƒ€ì…ì¸ ê²½ìš°
        elif isinstance(value, (int, float, bool)):
            summary_lines.append(
                f"- `{var_name}`: {type_name}, value={value}"
            )
        # Moduleì¸ ê²½ìš°
        elif type_name == 'module':
            module_name = getattr(value, '__name__', 'unknown')
            summary_lines.append(
                f"- `{var_name}`: imported module '{module_name}'"
            )
        # ê¸°íƒ€
        else:
            summary_lines.append(
                f"- `{var_name}`: {type_name}"
            )
    
    return "\n".join(summary_lines) if summary_lines else "No variables in context yet."


class AgentState(TypedDict):
    user_query: str
    rag_schema_context: str
    relative_tables: List[Dict[str, Any]]
    sql_queries: List[Dict[str, str]]
    sql_validation: Dict[str, Any]
    python_code: str
    python_execution_result: str
    python_validation: Dict[str, Any] # ì¶”ê°€
    final_result: str
    error: str
    retry_count: int
    max_retries: int
    sql_feedback: str
    python_error_feedback: str
    python_validation_feedback: str # ì¶”ê°€
    # Iterative Python Execution State
    python_plan: List[str]
    current_step_index: int
    python_context: Dict[str, Any]
    step_code: str
    step_result: str
    step_validation: Dict[str, Any]
    step_retry_count: int  # í˜„ì¬ ë‹¨ê³„ ì¬ì‹œë„ íšŸìˆ˜
    max_step_retries: int  # ë‹¨ê³„ë³„ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜


def search_relative_tables_node(state: AgentState):
    print("---ë…¸ë“œ: ê´€ë ¨ í…Œì´ë¸” ê²€ìƒ‰---")
    prompt = PromptTemplate(
        template=PROMPT_SEARCH_RELATIVE_TABLES,
        input_variables=["user_query", "rag_schema_context"],
    )
    chain = prompt | llm | JsonOutputParser()
    result = chain.invoke({
        "user_query": state["user_query"],
        "rag_schema_context": state["rag_schema_context"]
    })
    save_result(result, "relative_tables.json", True)
    return {"relative_tables": result}


def generate_sql_queries_node(state: AgentState):
    print("---ë…¸ë“œ: SQL ì¿¼ë¦¬ ìƒì„±---")
    prompt = PromptTemplate(
        template=PROMPT_GENERATE_SQL_QUERY,
        input_variables=["user_query", "relative_tables", "business_rules"],
    )
    chain = prompt | llm | JsonOutputParser()
    feedback = state.get("sql_feedback", "")
    if feedback:
        feedback = f"ì´ì „ì— ìƒì„±í•œ ê²°ê³¼ì™€ í”¼ë“œë°±:\n{state.get('sql_queries')}\n{feedback}"
    # Retrieve relevant business rules for SQL
    business_rules = retrieve_relevant_rules(state["user_query"], category="sql", rule_type="business")
    
    result = chain.invoke({
        "user_query": state["user_query"],
        "relative_tables": state["relative_tables"],
        "business_rules": business_rules,
        "sql_feedback": feedback,
    })
    save_result(result, "sql_query.json", True)
    return {"sql_queries": result, "sql_feedback": ""}  # í”¼ë“œë°± ì‚¬ìš© í›„ ì´ˆê¸°í™”


def validate_sql_query_node(state: AgentState):
    print("---ë…¸ë“œ: SQL ì¿¼ë¦¬ ê²€ì¦---")
    prompt = PromptTemplate(
        template=PROMPT_VALIDATE_SQL_QUERY,
        input_variables=["user_query", "sql_queries", "relative_tables", "business_rules"],
    )
    chain = prompt | llm | JsonOutputParser()
    # Retrieve relevant business rules for SQL validation
    business_rules = retrieve_relevant_rules(state["user_query"], category="sql", rule_type="business")

    result = chain.invoke({
        "user_query": state["user_query"],
        "relative_tables": state["relative_tables"],
        "business_rules": business_rules,
        "sql_queries": state["sql_queries"],
    })
    save_result(result, "sql_validation.json", False)   # ê²€ì¦ ì‹¤íŒ¨ ì‹œ ì•„ë˜ì—ì„œ í”¼ë“œë°± print()
    return {"sql_validation": result}


def decide_sql_revalidation(state: AgentState):
    print("---ì—£ì§€: SQL ì¬ê²€ì¦ ê²°ì •---")
    if state["sql_validation"]["is_valid"]:
        return "plan_python_analysis"
    else:
        return "handle_sql_feedback"


def handle_sql_feedback_node(state: AgentState):
    print("---ë…¸ë“œ: SQL í”¼ë“œë°± ì²˜ë¦¬---")
    retry_count = state.get("retry_count", 0) + 1
    feedback = state["sql_validation"]["feedback"]
    print(f"SQL ê²€ì¦ ì‹¤íŒ¨ í”¼ë“œë°±: {feedback}, ì¬ì‹œë„ íšŸìˆ˜: {retry_count}")
    return {"retry_count": retry_count, "sql_feedback": feedback}


def plan_python_analysis_node(state: AgentState):
    print("---ë…¸ë“œ: Python ë¶„ì„ ê³„íš ìˆ˜ë¦½---")
    prompt = PromptTemplate(
        template=PROMPT_PLAN_PYTHON_ANALYSIS,
        input_variables=["user_query", "relative_tables", "business_rules", "sql_queries"],
    )
    chain = prompt | llm | StrOutputParser()
    
    # ê³„íš ë‹¨ê³„ì—ì„œëŠ” ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ë§Œ í•„ìš” (ë¬´ì—‡ì„ í•´ì•¼ í•˜ëŠ”ì§€)
    business_rules = retrieve_relevant_rules(state["user_query"], category="common", rule_type="business")
    
    raw_result = chain.invoke({
        "user_query": state["user_query"],
        "relative_tables": state["relative_tables"],
        "business_rules": business_rules,
        "sql_queries": state["sql_queries"]
    })
    
    # JSON íŒŒì‹± ì‹œë„ (Markdown ì½”ë“œ ë¸”ë¡ ì œê±° ë° ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ)
    try:
        # ```json ... ``` ë˜ëŠ” [...] íŒ¨í„´ ì°¾ê¸°
        json_match = re.search(r'\[.*\]', raw_result, re.DOTALL)
        if json_match:
            json_str = json_match.group(0)
            result = json.loads(json_str)
        else:
            # JSON íŒ¨í„´ì„ ëª» ì°¾ìœ¼ë©´ ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ ì¤„ë°”ê¿ˆìœ¼ë¡œ ë¶„ë¦¬í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ (fallback)
            print("âš ï¸ ê³„íš íŒŒì‹± ê²½ê³ : JSON ë¦¬ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ í…ìŠ¤íŠ¸ë¥¼ ì¤„ ë‹¨ìœ„ë¡œ ë¶„ë¦¬í•©ë‹ˆë‹¤.")
            result = [line.strip() for line in raw_result.split('\n') if line.strip() and not line.strip().startswith('```')]
            
    except json.JSONDecodeError as e:
        print(f"âš ï¸ ê³„íš íŒŒì‹± ì—ëŸ¬: {e}. í…ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
        result = [line.strip() for line in raw_result.split('\n') if line.strip() and not line.strip().startswith('```')]

    save_result(result, "python_plan.json", True)
    
    # í…Œì´ë¸” ìŠ¤í‚¤ë§ˆë¥¼ python_contextì— í¬í•¨ (ì½”ë“œ ìƒì„± ì‹œ ì°¸ì¡°ìš©)
    schema_info = {
        "_table_schemas": state["relative_tables"],
        "sql_queries": state["sql_queries"],  # SQL ì¿¼ë¦¬ ë¦¬ìŠ¤íŠ¸ ì¶”ê°€
        "__builtins__": __builtins__
    }
    
    return {
        "python_plan": result,
        "current_step_index": 0,
        "python_context": schema_info,
        "python_code": "",
        "python_execution_result": "",
        "step_retry_count": 0,  # ì´ˆê¸° retry count
        "max_step_retries": 3   # ë‹¨ê³„ë³„ ìµœëŒ€ 3íšŒ ì¬ì‹œë„
    }


def generate_python_step_code_node(state: AgentState):
    """Generate code for the current step."""
    current_index = state["current_step_index"]
    plan = state["python_plan"]
    current_step = plan[current_index]
    
    print(f"---ë…¸ë“œ: Python ë‹¨ê³„ ì½”ë“œ ìƒì„± ({current_index + 1}/{len(plan)}) : {current_step}---")
    
    prompt = PromptTemplate(
        template=PROMPT_GENERATE_PYTHON_STEP,
        input_variables=["user_query", "business_rules", "python_rules", "python_plan", "current_step", "python_context", "step_feedback"],
    )
    chain = prompt | llm | StrOutputParser()
    
    # í˜„ì¬ ë‹¨ê³„ contextë¥¼ í¬í•¨í•˜ì—¬ ë” ì •í™•í•œ ê·œì¹™ ê²€ìƒ‰
    combined_query = f"{state['user_query']} {current_step}"
    
    # ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ (ë©”íŠ¸ë¦­ ì •ì˜, ë°ì´í„° ê´€ê³„ ë“±)
    business_rules = retrieve_relevant_rules(combined_query, category="common", rule_type="business")
    # Python ê·œì¹™ (Block Logic êµ¬í˜„, ì½”ë“œ ì‘ì„± ê°€ì´ë“œë¼ì¸ ë“±)
    python_rules = retrieve_relevant_rules(combined_query, category="python", rule_type="python")
    
    # âœ… ê°œì„ ëœ ì»¨í…ìŠ¤íŠ¸ ìš”ì•½ - DataFrame êµ¬ì¡°, ë³€ìˆ˜ ê°’ ë“± ìƒì„¸ ì •ë³´ ì œê³µ
    context_summary = summarize_context_for_llm(state["python_context"])
    
    # Get feedback if retry
    step_feedback = state.get("step_validation", {}).get("feedback", "")
    if step_feedback:
        step_feedback = f"ì´ì „ ì‹œë„ í”¼ë“œë°±:\n{step_feedback}"
    
    raw_output = chain.invoke({
        "user_query": state["user_query"],
        "business_rules": business_rules,
        "python_rules": python_rules,
        "python_plan": plan,
        "current_step": current_step,
        "python_context": context_summary,
        "step_feedback": step_feedback
    })
    
    # Retry count ì¦ê°€
    current_retry = state.get("step_retry_count", 0)
    
    # Parse JSON output with CoT reasoning
    clean_code = ""
    reasoning = ""
    approach = ""
    expected_output = ""
    potential_issues = ""
    try:
        # Try to extract JSON from response
        json_match = re.search(r'\{[\s\S]*"code"[\s\S]*\}', raw_output)  # â† raw_outputì€ chain.invoke() ê²°ê³¼
        if json_match:
            json_str = json_match.group(0)
            result = json.loads(json_str)
            
            # Extract fields
            reasoning = result.get("reasoning", "")
            approach = result.get("approach", "")
            expected_output = result.get("expected_output", "")
            potential_issues = result.get("potential_issues", "")
            clean_code = result.get("code", "")
            
            # Log CoT reasoning
            print(f"\nğŸ§  ì¶”ë¡ : {reasoning}")
            print(f"ğŸ“ ì ‘ê·¼ë²•: {approach}")
            if potential_issues:
                print(f"âš ï¸  ì˜ˆìƒ ë¬¸ì œ: {potential_issues}\n")
        else:
            # Fallback
            print("âš ï¸  JSON íŒŒì‹± ì‹¤íŒ¨, ì¼ë°˜ ì½”ë“œë¡œ ì²˜ë¦¬")
            clean_code = re.sub(r"```(?:python)?\s*([\s\S]*?)\s*```", r"\1", raw_output).strip()
            
    except json.JSONDecodeError as e:
        print(f"âš ï¸  JSON ì—ëŸ¬: {e}, í´ë°± ì²˜ë¦¬")
        clean_code = re.sub(r"```(?:python)?\s*([\s\S]*?)\s*```", r"\1", raw_output).strip()
    print(f"\nìƒì„±ëœ ì½”ë“œ:\n{clean_code}")
    
    # í”„ë¡¬í”„íŠ¸ ë° ê²°ê³¼ ë¡œê¹…
    log_data = {
        "step": f"{current_index + 1}/{len(plan)}",
        "step_description": current_step,
        "retry_count": current_retry,
        "cot_reasoning": {  # â† ìƒˆë¡œ ì¶”ê°€
            "reasoning": reasoning,
            "approach": approach,
            "expected_output": expected_output,
            "potential_issues": potential_issues
        },
        "prompt_inputs": {
            "user_query": state["user_query"],
            "current_step": current_step,
            "business_rules": business_rules[:200] + "..." if len(business_rules) > 200 else business_rules,
            "python_rules": python_rules[:200] + "..." if len(python_rules) > 200 else python_rules,
            "context_summary": context_summary[:300] + "..." if len(context_summary) > 300 else context_summary,
            "step_feedback": step_feedback[:200] + "..." if step_feedback and len(step_feedback) > 200 else step_feedback
        },
        "generated_code": clean_code
    }
    save_result(log_data, f"step_{current_index + 1}_code_gen_retry_{current_retry}.json", False)
    
    return {
        "step_code": clean_code,
        "step_validation": {},  # Clear validation to prevent stale feedback
        "step_retry_count": current_retry + 1  # ì¬ì‹œë„ ì¹´ìš´íŠ¸ ì¦ê°€
    }


def execute_python_step_node(state: AgentState):
    """Execute the generated code for the current step."""
    current_index = state["current_step_index"]
    plan = state["python_plan"]
    current_step = plan[current_index]
    
    print(f"---ë…¸ë“œ: Python ë‹¨ê³„ ì‹¤í–‰ ({current_index + 1}/{len(plan)}) : {current_step}---")
    
    # Execute the code
    execution_output = run_dynamic_code(state["step_code"], context=state["python_context"])
    
    # Merge new locals into context
    if execution_output["local_env"]:
        state["python_context"].update(execution_output["local_env"])
        
    step_result = execution_output["captured_output"] or ""
    error = execution_output["error"]
    
    if error:
        step_result += f"\nError: {str(error)}"
        print(f"ì‹¤í–‰ ì˜¤ë¥˜: {error}")
    else:
        print(f"ì‹¤í–‰ ê²°ê³¼:\n{step_result}")

    # Accumulate code
    new_accumulated_code = state["python_code"] + "\n\n" + f"# Step: {current_step}\n" + state["step_code"]
        
    return {
        "step_result": step_result,
        "python_code": new_accumulated_code,
        "python_context": state["python_context"]
    }


def validate_python_step_node(state: AgentState):
    print("---ë…¸ë“œ: Python ë‹¨ê³„ ê²€ì¦---")
    current_index = state["current_step_index"]
    plan = state["python_plan"]
    current_step = plan[current_index]
    
    prompt = PromptTemplate(
        template=PROMPT_VALIDATE_PYTHON_STEP,
        input_variables=["user_query", "business_rules", "python_rules", "current_step", "step_code", "step_result"],
    )
    chain = prompt | llm | JsonOutputParser()
    
    # í˜„ì¬ ë‹¨ê³„ contextë¥¼ í¬í•¨í•˜ì—¬ ë” ì •í™•í•œ ê·œì¹™ ê²€ìƒ‰
    combined_query = f"{state['user_query']} {current_step}"
    
    # ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ (ë©”íŠ¸ë¦­ ì •ì˜, ë°ì´í„° ê´€ê³„ ë“±)
    business_rules = retrieve_relevant_rules(combined_query, category="common", rule_type="business")
    # Python ê·œì¹™ (Block Logic êµ¬í˜„, ì½”ë“œ ì‘ì„± ê°€ì´ë“œë¼ì¸ ë“±)
    python_rules = retrieve_relevant_rules(combined_query, category="python", rule_type="python")
    
    result = chain.invoke({
        "user_query": state["user_query"],
        "business_rules": business_rules,
        "python_rules": python_rules,
        "current_step": current_step,
        "step_code": state["step_code"],
        "step_result": state["step_result"]
    })
    
    print(f"ê²€ì¦ ê²°ê³¼: {result}")
    return {"step_validation": result}


def check_step_result(state: AgentState):
    print("---ì—£ì§€: ë‹¨ê³„ ê²°ê³¼ í™•ì¸---")
    validation = state["step_validation"]
    
    if validation["is_valid"]:
        next_index = state["current_step_index"] + 1
        state["python_execution_result"] += "\n\n" + state["step_result"]
        if next_index < len(state["python_plan"]):
            print(f"ë‹¤ìŒ ë‹¨ê³„ë¡œ ì´ë™: {next_index + 1}/{len(state['python_plan'])}")
            return "next_step"
        else:
            print("ëª¨ë“  ë‹¨ê³„ ì™„ë£Œ, ìµœì¢… ê²°ê³¼ ìƒì„±")
            return "finalize"
    else:
        # Check retry limit
        retry_count = state.get("step_retry_count", 0)
        max_retries = state.get("max_step_retries", 3)
        
        if retry_count >= max_retries:
            print(f"âš ï¸  ë‹¨ê³„ ì¬ì‹œë„ í•œê³„ ì´ˆê³¼ ({retry_count}/{max_retries}). ìµœì¢… ê²°ê³¼ë¡œ ì´ë™.")
            return "finalize"  # ì¬ì‹œë„ í•œê³„ ì´ˆê³¼ ì‹œ ê°•ì œë¡œ ì¢…ë£Œ
        else:
            print(f"í˜„ì¬ ë‹¨ê³„ ì¬ì‹œë„: {retry_count + 1}/{max_retries} (ë‹¨ê³„: {state['current_step_index'] + 1}/{len(state['python_plan'])})")
            return "retry_step"


def increment_step_index_node(state: AgentState):
    """Move to next step by incrementing the index."""
    next_index = state["current_step_index"] + 1
    print(f"Step index incremented: {state['current_step_index']} -> {next_index}")
    return {
        "current_step_index": next_index,
        "step_retry_count": 0  # ìƒˆ ë‹¨ê³„ë¡œ ì´ë™ ì‹œ retry count ì´ˆê¸°í™”
    }


# TODO
def generate_final_result_node(state: AgentState):
    print("---ë…¸ë“œ: ìµœì¢… ê²°ê³¼ ìƒì„±---")
    prompt = PromptTemplate(
        template=PROMPT_GENERATE_FINAL_RESULT,
        input_variables=["python_execution_result", "error_message"],
    )
    chain = prompt | llm | StrOutputParser()
    result = chain.invoke({
        "python_execution_result": state.get("python_execution_result", ""),
        "error_message": state.get("error", "")
    })
    save_result(result, "final_result.txt", True)
    return {"final_result": result}


# === LangGraph ì›Œí¬í”Œë¡œìš° ì •ì˜ ===

# ê·¸ë˜í”„ ì´ˆê¸°í™”
workflow = StateGraph(AgentState)

# --- ë…¸ë“œ ì •ì˜ ---
workflow.add_node("search_relative_tables", search_relative_tables_node)
workflow.add_node("generate_sql_queries", generate_sql_queries_node)
workflow.add_node("validate_sql_query", validate_sql_query_node)
workflow.add_node("handle_sql_feedback", handle_sql_feedback_node)
# Iterative Python Execution Nodes
workflow.add_node("plan_python_analysis", plan_python_analysis_node)
workflow.add_node("generate_python_step_code", generate_python_step_code_node)
workflow.add_node("execute_python_step", execute_python_step_node)
workflow.add_node("validate_python_step", validate_python_step_node)
workflow.add_node("increment_step_index", increment_step_index_node)
workflow.add_node("generate_final_result", generate_final_result_node)

# --- ì—£ì§€ ì¡°ê±´ë¶€ í•¨ìˆ˜ ì •ì˜ ---
def decide_sql_retry(state: AgentState):
    print("---ì—£ì§€: SQL ì¬ì‹œë„ ê²°ì •---")
    if state["retry_count"] > state["max_retries"]:
        return "end_with_error"
    else:
        return "generate_sql_queries"

# --- ì—£ì§€ ì¶”ê°€ ---
workflow.set_entry_point("search_relative_tables")
workflow.add_edge("search_relative_tables", "generate_sql_queries")
workflow.add_edge("generate_sql_queries", "validate_sql_query")

# SQL ê²€ì¦ ê²°ê³¼ì— ë”°ë¥¸ ì¡°ê±´ë¶€ ì—£ì§€
workflow.add_conditional_edges(
    "validate_sql_query",
    decide_sql_revalidation,
    {
        "plan_python_analysis": "plan_python_analysis",  # Use iterative approach
        "handle_sql_feedback": "handle_sql_feedback",
    },
)

# SQL í”¼ë“œë°± ì²˜ë¦¬ í›„ ì¬ì‹œë„ ì—¬ë¶€ ê²°ì • ì—£ì§€
workflow.add_conditional_edges(
    "handle_sql_feedback",
    decide_sql_retry,
    {
        "generate_sql_queries": "generate_sql_queries", # ì¬ì‹œë„
        "end_with_error": "end_with_error",             # ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼ ì‹œ
    },
)

# Iterative Python Execution Workflow
workflow.add_edge("plan_python_analysis", "generate_python_step_code")
workflow.add_edge("generate_python_step_code", "execute_python_step")
workflow.add_edge("execute_python_step", "validate_python_step")

workflow.add_conditional_edges(
    "validate_python_step",
    check_step_result,
    {
        "next_step": "increment_step_index",  # Increment and move to next step
        "retry_step": "generate_python_step_code",  # Retry: regenerate code
        "finalize": "generate_final_result",  # All steps complete
    },
)

workflow.add_edge("increment_step_index", "generate_python_step_code")

# ìµœì¢… ê²°ê³¼ ìƒì„± ë° ì˜¤ë¥˜ ì¢…ë£Œ ì—£ì§€
workflow.add_edge("generate_final_result", END)
workflow.add_node("end_with_error", generate_final_result_node) # ìµœì¢… ì˜¤ë¥˜ ì²˜ë¦¬ ë…¸ë“œ
workflow.add_edge("end_with_error", END)

# ê·¸ë˜í”„ ì»´íŒŒì¼
app = workflow.compile()


if __name__ == "__main__":
    user_query = input("ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? ")
    
    # ë””ë²„ê·¸: ì…ë ¥ê°’ í™•ì¸
    # print(f"\n[DEBUG] ë°›ì€ ì§ˆë¬¸: {user_query}")
    # print(f"[DEBUG] ì§ˆë¬¸ ê¸¸ì´: {len(user_query)}ì")
    # print(f"[DEBUG] ì§ˆë¬¸ repr: {repr(user_query)}\n")
    
    initial_state = {
        "user_query": user_query,
        "rag_schema_context": STATE["rag_schema_context"],
        "retry_count": 0,
        "max_retries": 3,
        "sql_feedback": "",
        "python_error_feedback": ""
    }
    final_state = app.invoke(initial_state, config={"recursion_limit": 150})
    print("\n--- ìµœì¢… ê²°ê³¼ ---")
    print(final_state.get("final_result", "ì˜¤ë¥˜ë¡œ ì¸í•´ ìµœì¢… ê²°ê³¼ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."))
